def jobDir = "conf/jobs"

// Have this script clean up the jobDir on ligradle clean.
clean {
  delete jobDir
}

// Spark parameters
def executorMemoryInMB = 8000
def executorMemory = "${executorMemoryInMB}m" as String
def executorMemoryOverhead = executorMemoryInMB / 4
def numExecutorsList = [60, 90, 120, 180, 240]
def driverMemoryInMB = 8000
def driverMemory = "${driverMemoryInMB}m" as String


// Game input data parameters
def trainInputDirs = "/jobs/liar/yma/jymbii-batch/v2_data/glmix_data_20000"
def trainDateRange = "20151001-20160131"

def flowName = "game-speed-up-experiment-on-jymbii-data-set-$trainDateRange" as String


def featureNameAndTermSetInputPath = "/jobs/liar/jymbii-glmm/glmix/feature-lists/" +
    "globalFeatures-memberFeatures-jobFeatures-memberJobCrossFeatures-20150707-20151103"

def outputRoot = "/jobs/liar/glmix_results/JYMBII/$flowName" as String


// Game data configuration parameters
def featureShardIdToFeatureSectionKeysMap = "shard1:globalFeatures,memberFeatures,jobFeatures,memberJobCrossFeatures|" +
    "shard2:globalFeatures,jobFeatures|shard3:globalFeatures,memberFeatures"
def numPartitionsForFixedEffectDataSet = 240 * 3
def numPartitionsForRandomEffectDataSet = 240 * 3
def fixedEffectDataConfigurations = "global:shard1,$numPartitionsForFixedEffectDataSet" as String
def numFeaturesToNumObservationsRatio = -1
def randomEffectDataConfigurations =
    "per-member:memberId,shard2,$numPartitionsForRandomEffectDataSet,-1,0,$numFeaturesToNumObservationsRatio,index_map|" +
        "per-job:jobId,shard3,$numPartitionsForRandomEffectDataSet,-1,0,$numFeaturesToNumObservationsRatio,index_map"


// Game optimization parameters
def numIterations = 1
def updatingSequence = "global,per-member,per-job"
def fixedEffectOptimizationConfigurations = "global:10,1e-10,10,1,tron,l2"
def perMemberRandomEffectRegularizationWeight = 10
def perJobRandomEffectRegularizationWeight = 30
def randomEffectOptimizationConfigurations = "per-member:20,1e-10,$perMemberRandomEffectRegularizationWeight,1,tron,l2|" +
    "per-job:20,1e-10,$perJobRandomEffectRegularizationWeight,1,tron,l2"


hadoop {
  buildPath jobDir

  workflow(flowName) {

    for (numExecutors in numExecutorsList) {

      def parallelism = numExecutors * 3
      def applicationName = numExecutors as String

      job(applicationName) {
        def jobOutputDir="$outputRoot/$applicationName" as String

        baseProperties 'sparkCommon'
        set properties: ['class'                                  : 'com.linkedin.photon.ml.avro.training.Driver',
                         'num-executors'                          : numExecutors,
                         'driver-memory'                          : driverMemory,
                         'executor-memory'                        : executorMemory,
                         'conf.spark.yarn.executor.memoryOverhead': executorMemoryOverhead,
                         'conf.spark.default.parallelism'         : parallelism,
                         'params'                                 : "--train-input-dirs $trainInputDirs " + "--train-date-range $trainDateRange " +
                             "--task-type logistic_regression "+
                             "--output-dir $jobOutputDir " + "--feature-name-and-term-set-path $featureNameAndTermSetInputPath " +
                             "--feature-shard-id-to-feature-section-keys-map $featureShardIdToFeatureSectionKeysMap " +
                             "--num-iterations $numIterations " + "--updating-sequence $updatingSequence " + "--fixed-effect-optimization-configurations $fixedEffectOptimizationConfigurations " +
                             "--fixed-effect-data-configurations $fixedEffectDataConfigurations " + "--random-effect-optimization-configurations $randomEffectOptimizationConfigurations " +
                             "--random-effect-data-configurations $randomEffectDataConfigurations " +
                             "--save-models-to-hdfs false " + "--application-name $applicationName "]
      }
      targets applicationName
    }
  }
}