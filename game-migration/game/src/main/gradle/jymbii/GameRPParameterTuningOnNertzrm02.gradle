def jobDir = "conf/jobs"

// Have this script clean up the jobDir on ligradle clean.
clean {
  delete jobDir
}

def flowName = "game-full-on-jymbii-4-month-parameter-tuning-pro-50"

def trainInputDirs = "/jobs/liar/yma/jymbii-batch-wk/v2_data/glmix_data_20000,/jobs/liar/yma/jymbii-batch/v2_data/" +
    "glmix_data_20000"
def validateInputDirs = "/jobs/liar/yma/jymbii-batch/v2_data/glmix_data_20000"

def trainDateRange = "20150707-20151103"
def validateDateRange = "20151104-20151110"


def featureNameAndTermSetInputPath = "/jobs/liar/jymbii-glmm/glmix/feature-lists/" +
    "globalFeatures-memberFeatures-jobFeatures-memberJobCrossFeatures-20150707-20151103"

def featureShardIdToFeatureSectionKeysMap = "shard1:globalFeatures,memberFeatures,jobFeatures,memberJobCrossFeatures|" +
    "shard2:globalFeatures,jobFeatures|shard3:globalFeatures,memberFeatures"

def outputDir = "/tmp/liar/jobs/liar/$flowName" as String


def numIterations = 4
def updatingSequence = "global,per-member-rp,per-member,per-job-rp,per-job"
def fixedEffectOptimizationConfigurations = "global:10,1e-5,10,0.5,tron,l2"
def fixedEffectDataConfigurations = "global:shard1"

def perMemberRandomEffectRegularizationWeights = [30, 50, 100]
def perJobRandomEffectRegularizationWeights = [30, 50, 100]

def rpRegularizationWeightRatios = [2, 5]

def numFeaturesToNumObservationsRatios = [20]
def numProjectedDimensions = [50]


hadoop {
  buildPath jobDir

  workflow(flowName) {

    for (rpRegularizationWeightRatio in rpRegularizationWeightRatios) {
      for (numProjectedDimension in numProjectedDimensions) {
        for (numFeaturesToNumObservationsRatio in numFeaturesToNumObservationsRatios) {
          for (perMemberRandomEffectRegularizationWeight in perMemberRandomEffectRegularizationWeights) {
            for (perJobRandomEffectRegularizationWeight in perJobRandomEffectRegularizationWeights) {

              if (perMemberRandomEffectRegularizationWeight > perJobRandomEffectRegularizationWeight) {
                continue
              }

              def perMemberRPRandomEffectRegularizationWeight = perMemberRandomEffectRegularizationWeight / rpRegularizationWeightRatio
              def perJobPRandomEffectRegularizationWeight = perJobRandomEffectRegularizationWeight / rpRegularizationWeightRatio

              def randomEffectDataConfigurations = "per-member-rp:memberId,shard2,-1,-1,-1,random=$numProjectedDimension" +
                  "|per-member:memberId,shard2,-1,-1,$numFeaturesToNumObservationsRatio,index_map" +
                  "|per-job-rp:jobId,shard3,-1,-1,-1,random=$numProjectedDimension" +
                  "|per-job:jobId,shard3,-1,-1,$numFeaturesToNumObservationsRatio,index_map"

              def randomEffectOptimizationConfigurations =
                  "per-member-rp:10,1e-5,$perMemberRPRandomEffectRegularizationWeight,1,tron,l2" +
                      "|per-member:10,1e-5,$perMemberRandomEffectRegularizationWeight,1,tron,l2" +
                      "|per-job-rp:10,1e-5,$perJobPRandomEffectRegularizationWeight,1,tron,l2" +
                      "|per-job:10,1e-5,$perJobRandomEffectRegularizationWeight,1,tron,l2"

              def applicationName = "member-$perMemberRandomEffectRegularizationWeight-member-pro-$perMemberRPRandomEffectRegularizationWeight-job-$perJobRandomEffectRegularizationWeight-job-pro-$perJobPRandomEffectRegularizationWeight-ratio-$numFeaturesToNumObservationsRatio-pro-$numProjectedDimension"
                  .replaceAll("\\.|_|,", "-") as String

              job(applicationName) {

                def executorMemoryInMB = 8000
                def executorMemory = "${executorMemoryInMB}m" as String
                def executorMemoryOverhead = executorMemoryInMB / 4
                def numExecutors = 150
                def driverMemoryInMB = 8000
                def driverMemory = "${driverMemoryInMB}m" as String
                def parallelism = numExecutors * 4

                def jobOutputDir = "$outputDir/$applicationName" as String

                baseProperties 'sparkCommon'
                set properties: ['class'                                  : 'com.linkedin.photon.ml.avro.training.Driver',
                                 'num-executors'                          : numExecutors,
                                 'driver-memory'                          : driverMemory,
                                 'executor-memory'                        : executorMemory,
                                 'conf.spark.yarn.executor.memoryOverhead': executorMemoryOverhead,
                                 'conf.spark.default.parallelism'         : parallelism,
                                 'params'                                 : "--train-input-dirs $trainInputDirs " +
                                     "--task-type logistic_regression " +
                                     "--validate-input-dirs $validateInputDirs " +
                                     "--train-date-range $trainDateRange " +
                                     "--validate-date-range $validateDateRange " +
                                     "--output-dir $jobOutputDir " +
                                     "--feature-name-and-term-set-path $featureNameAndTermSetInputPath " +
                                     "--feature-shard-id-to-feature-section-keys-map $featureShardIdToFeatureSectionKeysMap " +
                                     "--num-iterations $numIterations " +
                                     "--updating-sequence $updatingSequence " +
                                     "--fixed-effect-optimization-configurations $fixedEffectOptimizationConfigurations " +
                                     "--fixed-effect-data-configurations $fixedEffectDataConfigurations " +
                                     "--random-effect-optimization-configurations $randomEffectOptimizationConfigurations " +
                                     "--random-effect-data-configurations $randomEffectDataConfigurations " +
                                     "--application-name $applicationName "]
              }
              targets applicationName
            }
          }
        }
      }
    }
  }
}